# -*- coding: utf-8 -*-
"""q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z74r6RbVTIYI4xbHlmK8rw8DUu1THjal
"""

import cv2
import numpy as np
import matplotlib.pyplot as mp

cv2.__version__

img_l = cv2.imread('Q2/left.png',1)
img_l = cv2.cvtColor(img_l, cv2.COLOR_BGR2RGB)
gray_l = cv2.cvtColor(img_l, cv2.COLOR_BGR2GRAY)
img_r = cv2.imread('Q2/right.png',1)
img_r = cv2.cvtColor(img_r, cv2.COLOR_BGR2RGB)
gray_r = cv2.cvtColor(img_r, cv2.COLOR_BGR2GRAY)
np.shape(img_l)

mp.imshow(img_l, cmap = 'gray', interpolation = 'bicubic')

mp.imshow(img_r, cmap = 'gray', interpolation = 'bicubic')

"""opencv version has been downgraded to 3.4.2 in order to use sift"""

sift = cv2.xfeatures2d.SIFT_create()
keypoints_l, descriptors_l = sift.detectAndCompute(img_l, None)
keypoints_r, descriptors_r = sift.detectAndCompute(img_r, None)
# keypoints from KeyPoint objects to NumPy arrays
kpl = np.float32([kp.pt for kp in keypoints_l])
kpr = np.float32([kp.pt for kp in keypoints_r])

"""Descriptors in left image"""

img_l_kp = cv2.drawKeypoints(gray_l,keypoints_l,np.copy(img_l))
mp.imshow(img_l_kp)

"""Descriptors in right image"""

img_r_kp = cv2.drawKeypoints(gray_r,keypoints_r,np.copy(img_r))
mp.imshow(img_r_kp)

"""Registration

Matching features together is actually a fairly straightforward process. We simply loop over the descriptors from both images, compute the distances, and find the smallest distance for each pair of descriptors. Since this is a very common practice in computer vision, OpenCV has a built-in function called cv2.DescriptorMatcher_create
that constructs the feature matcher for us. The BruteForce
value indicates that we are going to exhaustively compute the Euclidean distance between all feature vectors from both images and find the pairs of descriptors that have the smallest distance.
"""

#creating object of descriptor 'bruteforce type
matcher = cv2.DescriptorMatcher_create("BruteForce")

rawMatches = matcher.knnMatch(descriptors_r,descriptors_l,k=2)

# img3 = cv2.drawMatchesKnn(img_l,kpl,img_r,kpr,rawMatches,None)

# mp.imshow(img3)

"""lowe's ratio"""

accp_match = []
for m in rawMatches:
    if len(m) == 2 and m[0].distance < m[1].distance * 0.7:
        accp_match.append((m[0].trainIdx, m[0].queryIdx))

MIN_MATCH = 10
if len(accp_match)>MIN_MATCH:
    src_pts = np.float32([kpr[i] for (_, i) in accp_match])
    dst_pts = np.float32([kpl[i] for (i, _) in accp_match])
    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,4.0)
else:
    print( "Not enough matches are found - {}/{}".format(len(accp_match), MIN_MATCH) )
    matchesMask = None

result = cv2.warpPerspective(img_r, M, (img_r.shape[1] + img_l.shape[1], img_r.shape[0]))
result[0:img_r.shape[0], 0:img_r.shape[1]] = img_l

"""Crop or resize the image as required"""

mp.imshow(result[:,:625])
mp.show()